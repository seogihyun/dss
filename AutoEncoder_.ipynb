{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoEncoder_.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPPUkYzQyG6c"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "tf.keras.utils.get_file('/content/bad_images.zip', 'http://bit.ly/35pHZlC', extract=True)\n",
        "\n",
        "!unzip /content/bad_images.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm7PKN-zysyA"
      },
      "source": [
        "import pathlib\n",
        "image_root = pathlib.Path('/content/images')\n",
        "\n",
        "all_image_paths = list(image_root.glob('*/*'))\n",
        "print(all_image_paths[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8oVBfhQzDJn"
      },
      "source": [
        "import PIL.Image as Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "for c in range(9):\n",
        "    plt.subplot(3,3,c+1)\n",
        "    plt.imshow(plt.imread(all_image_paths[c]))\n",
        "    plt.title(all_image_paths[c])\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3QEiw0gzTlX"
      },
      "source": [
        "train_path, valid_path, test_path = [], [], []\n",
        "\n",
        "for image_path in all_image_paths:\n",
        "    if str(image_path).split('.')[-1] != 'jpg':\n",
        "        continue\n",
        "    if str(image_path).split('/')[-2] == 'train':\n",
        "        train_path.append(str(image_path))\n",
        "    elif str(image_path).split('/')[-2] == 'val':\n",
        "        valid_path.append(str(image_path))\n",
        "    else:\n",
        "        test_path.append(str(image_path))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVk1ZQh2z0yZ"
      },
      "source": [
        "def get_hr_and_lr(image_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "    hr = tf.image.random_crop(img, [50, 50, 3])\n",
        "    lr = tf.image.resize(hr, [25, 25])\n",
        "    lr = tf.image.resize(lr, [50, 50])\n",
        "    return lr, hr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oQ1q4iP0Jm8"
      },
      "source": [
        "train_dataset = tf.data.Dataset.list_files(train_path)\n",
        "train_dataset = train_dataset.map(get_hr_and_lr)\n",
        "train_dataset = train_dataset.repeat()\n",
        "train_dataset = train_dataset.batch(16)\n",
        "\n",
        "valid_dataset = tf.data.Dataset.list_files(valid_path)\n",
        "valid_dataset = valid_dataset.map(get_hr_and_lr)\n",
        "valid_dataset = valid_dataset.repeat()\n",
        "valid_dataset = valid_dataset.batch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9q8z8gl0fl2"
      },
      "source": [
        "def REDNet(num_layers):\n",
        "    conv_layers = []\n",
        "    deconv_layers = []\n",
        "    residual_layers = []\n",
        "\n",
        "    inputs = tf.keras.layers.Input(shape=(None, None, 3))\n",
        "    conv_layers.append(tf.keras.layers.Conv2D(3, kernel_size=3, padding='same', activation='relu'))\n",
        "\n",
        "    for i in range(num_layers-1):\n",
        "        conv_layers.append(tf.keras.layers.Conv2D(64, kernel_size=3, padding='same', activation='relu'))\n",
        "        deconv_layers.append(tf.keras.layers.Conv2DTranspose(64, kernel_size=3, padding='same', activation='relu'))\n",
        "\n",
        "    deconv_layers.append(tf.keras.layers.Conv2DTranspose(3, kernel_size=3, padding='same'))\n",
        "\n",
        "    # 인코더 시작\n",
        "    x = conv_layers[0](inputs)\n",
        "\n",
        "    for i in range(num_layers-1):\n",
        "        x = conv_layers[i+1](x)\n",
        "        if i % 2 == 0:\n",
        "            residual_layers.append(x)\n",
        "\n",
        "    # 디코더 시작\n",
        "    for i in range(num_layers-1):\n",
        "        if i % 2 == 1:\n",
        "            x = tf.keras.layers.Add()([x, residual_layers.pop()])\n",
        "            x = tf.keras.layers.Activation('relu')(x)\n",
        "        x = deconv_layers[i](x)\n",
        "\n",
        "    x = deconv_layers[-1](x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqN8r7I52B-F"
      },
      "source": [
        "def psnr_metric(y_true, y_pred):\n",
        "    return tf.image.psnr(y_true, y_pred, max_val=1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7D7EKr32Kdl"
      },
      "source": [
        "model = REDNet(15)\n",
        "model.compile(optimizer=tf.optimizers.Adam(0.0001), loss='mse', metrics=[psnr_metric])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB3V5a8L2VBF"
      },
      "source": [
        "history = model.fit_generator(train_dataset,\n",
        "                               epochs=1000,\n",
        "                               steps_per_epoch=len(train_path)//16,\n",
        "                               validation_data=valid_dataset,\n",
        "                               validation_steps=len(valid_path),\n",
        "                               verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF8M9nzR2yY3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['psnr_metric'], 'b-', label='psnr')\n",
        "plt.plot(history.history['val_psnr_metric'], 'r--', label='val_psnr')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyMcAuhL31nD"
      },
      "source": [
        "img = tf.io.read_file(test_path[0])\n",
        "img = tf.image.decode_jpeg(img, channels=3)\n",
        "hr = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "lr = tf.image.resize(hr, [hr.shape[0]//2, hr.shape[1]//2])\n",
        "lr = tf.image.resize(lr, [hr.shape[0], hr.shape[1]])\n",
        "predict_hr = model.predict(np.expand_dims(lr, axis=0))\n",
        "\n",
        "print(tf.image.psnr(np.squeeze(predict_hr, axis=0), hr, max_val=1.0))\n",
        "print(tf.image.psnr(lr, hr, max_val=1.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6obPW2m4ZHV"
      },
      "source": [
        "plt.figure(figsize=(8,16))\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.imshow(hr)\n",
        "plt.title('original - hr')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.imshow(lr)\n",
        "plt.title('lr')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.imshow(np.squeeze(predict_hr, axis=0))\n",
        "plt.title('sr')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HueCVMhK4ql2"
      },
      "source": [
        "image_path = tf.keras.utils.get_file('butterfly.png', 'http://bit.ly/2oAOxgH')\n",
        "img = tf.io.read_file(image_path)\n",
        "img = tf.image.decode_jpeg(img, channels=3)\n",
        "hr = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "lr = tf.image.resize(hr, [hr.shape[0]//2, hr.shape[1]//2])\n",
        "lr = tf.image.resize(lr, [hr.shape[0], hr.shape[1]])\n",
        "predict_hr = model.predict(np.expand_dims(lr, axis=0))\n",
        "\n",
        "print(tf.image.psnr(np.squeeze(predict_hr, axis=0), hr, max_val=1.0))\n",
        "print(tf.image.psnr(lr, hr, max_val=1.0))\n",
        "\n",
        "plt.figure(figsize=(16,16))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(hr)\n",
        "plt.title('original - hr')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(lr)\n",
        "plt.title('lr')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(np.squeeze(predict_hr, axis=0))\n",
        "plt.title('sr')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSibQiqYFaNC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaMDlNWnJ_aE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}